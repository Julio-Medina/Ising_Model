\documentclass[a4paper]{article}
\usepackage[spanish,es-tabla]{babel}	% trabajar en español
\spanishsignitems	
%\usepackage{simplemargins}

%\usepackage[square]{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bbold}
\usepackage{graphicx}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{amsthm}
\newtheorem{theorem}{Teorema}
\newtheorem{lemma}{Lema}
\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{algpseudocode}
%\usepackage{algorithm2e}
\usepackage{booktabs}
\usepackage[export]{adjustbox}
\setcounter{MaxMatrixCols}{20}
\begin{document}
\pagenumbering{arabic}

\Large
 \begin{center}
\textbf{Simulación MC Modelo de Ising}\


\hspace{10pt}

% Author names and affiliations
\large
%Lic. Julio A. Medina$^1$ \\
Julio A. Medina \\
\hspace{10pt}
\small  
 Universidad de San Carlos\\
Escuela de Ciencias Físicas y Matemáticas\\
Maestría en Física\\
\href{mailto:julioantonio.medina@gmail.com}{julioantonio.medina@gmail.com}\\

\end{center}

\hspace{10pt}

\begin{abstract}
En mecánica estadística el Modelo de Ising para la modelación teórica de un material ferromagnético consiste en considerar las interacciones de corto rango del momento dipolar magnético de spins moleculares. Los spins se configuran en un retículo n-dimensional y están discretizados. Aquí se ha simulado el modelo de Ising por medio del método de Monte Carlo para analizar el comportamiento y determinar si hay transiciones de fase(transiciones continuas). Se encontraron transiciones de fase continuas y efectos del tamaño del retículo que pueden irse eliminando conforme se incrementa el tamaño del retículo.

\end{abstract}

\normalsize
\section{Introducción}
El modelo de Ising es el arquetipo para modelar el comportamiento de materiales ferromagnéticos y las transiciones de fase que puede darse en este tipo de materiales, particularmente el fenómeno de transición para-ferromagnética. Esto se puede observar fácilmente al tomar una pieza de hierro previamente magnetizado por algún campo magnético suficientemente grande para generar un imán temporal, al acercar este pedazo imantado a una fuente de calor se puede observar como rápidamente se pierden las propiedades magnéticas.
\subsection{Transiciones de fase}
Las transiciones de fase y los fenómenos críticos(\textit{critical phenomena}) están asociados a una gran variedad de sistemas físicos: Fluidos simples y mezclas de fluidos, materiales magnéticos, ferromagnetos, superfluidos, superconductores y otros. La tesis doctoral de van der Waals(1873) fue la primer teoría exitosa para explicar la continuidad de los estados líquidos y gaseosos de la materia. La transición al ferromagnetismo también fue explicada a principios del siglo XX por una teoría fenomenológica propuesta por Pierre Curie y desarrollada por Weiss que está íntimamente relacionada a la teoría de van der Waals. Estas son conocidas como teorías clásicas de transición de fase y todavía se usan para describir algunos aspectos cualitativos de todo tipo de sistemas.\\

Estas teorías clásicas fueron sometidas a un proceso de análisis más riguroso en los años 60´s. Varias cantidades termodinámicas como el calor específico, la compresibilidad y la susceptibilidad magnética presentan un comportamiento peculiar en la llamada región crítica, con divergencias asimptóticas caracterizadas por una colección de exponentes críticos. Rápidamente se reconoció que el comportamiento crítico de las cantidades termodinámicas equivalentes, exhiben una caracterización universal que se puede describir por los bien definidos exponentes críticos.  \\
\subsubsection{Fenomenología de Landau}
La teoría de Landau para transiciones de fases continuas se basa en la expansión de la energía libre en términos de las invariantes de los parámetros de orden. Por lo que se asume que la energía libre es una función analítica, incluso en la vecindad de un punto crítico. En muchos casos es relativamente sencillo  encontrar un número aceptable  de parámetros de orden asociados a una transición de fase. El parámetro de orden no es siempre un escalar, puede ser incluso un tensor para sistemas complejos. Generalmente se tiene que $\psi=0$ en la fase con mayor simetría que usualmente se presenta a altas temperaturas en la fase desordenada, y $\psi\neq0$ en la fase menos simétrica, mas ordenada.\\
Hay varios ejemplos de estos parámetros de orden:
\begin{itemize}
\item La transición de liquido-gas, donde $psi$ viene dado por $v_G-v_L$ o por $\rho_L-\rho_G$($v$ es el volumen especifico y $\rho$ es la densidad de partículas)
\item La transición para-ferromagnética en la cual el parámetro de orden $\psi$ puede ser el vector de magnetización(que se convierte en un escalar para sistema uniaxiales como en el modelo de Ising) en la ausencia de un campo aplicado.
\item La transición anti-ferromagnética  en la cual el parámetro de orden $\psi$ se puede asociar a la magnetización del sub-retículo.
\end{itemize}
La lista no es exhaustiva. Para un fluido puro, el parámetro de orden es un escalar y se puede escribir la expansión
\begin{equation}
g(T,p;\psi)=g_0(T,p)+g_1(T,p)\psi+g_2(T,p)\psi^2+g_3(T,p)\psi^3+g_4(T,p)\psi^4+\hdots,
\end{equation}
donde los coeficientes $g_n$ son funciones de los campos termodinámicos $T$ y $p$. Para obtener un punto crítico simple, es suficiente que $g_4$ sea positivo, esto garantiza la existencia de un mínimo con respecto a $\psi$, por lo que se omiten términos de orden superior en la expansión de Landau. Debido a que se tiene alguna libertad para escoger $\psi$, siempre es posible eliminar el termino cúbico en la expansión(ver \cite{Salinas}). Por lo que sin perdida de generalidad, se puede escribir la expansión como
\begin{equation}
g(T,p;\psi)=A_0(T,p)+A_1(T,p)\psi+A_2(T,p)\psi^2+\psi^4
\end{equation}
para tener un mínimo estable, los coeficientes $A_1$ y $A_2$ tienen que ser cero en el punto crítico, sin embargo es importante mencionar que la existencia de dicha expansión no puede darse por darse por sentada, siendo la solución analítica del modelo bidimensional de Ising un conocido contraejemplo.\\
Para un ferromagneto uniaxial, se tiene una expansión de Landau más simple(debido a la simetría), por lo que la energía libre de Helmholtz se puede escribir como
\begin{equation}
f(T,m)f_0(T)+A(T)m^2+B(T)m^4+\hdots
\end{equation}
con esto se obtiene
\begin{equation}
g(T,H,m)=f_0(T)-H m+A(T)m^2+B(T)m^4+\hdots
\end{equation}
En el punto crítico se tiene que $H=0$ y $A(T)=0$, en la vecindad del punto crítico se puede escribir
\begin{equation}
A(T)=a(T-T_c)
\end{equation}
con $a>0$, $B(T)=b>0$, y $f_0(T)\approx f_0 (T_c)$. Por lo que se puede escribir
\begin{equation}
g(T,H,m)=f_0(T_c)-H m+a(T-T_c)m^2+b m^4.
\end{equation}

\subsection{Modelo de Ising}
La mayoría de experimentos en la vecindad de los puntos críticos indican que los exponentes críticos asumen valores universales, que difieren bastante de las teorías clásicas(un ejemplo se presento en la fenomenología de Landau). Ahora se ha reconocido que los valores de los exponentes críticos dependen de solo unos cuantos ingredientes:
\begin{itemize}
\item La dimensión de los sistemas físicos.
\item La dimensión de los parámetros de orden. Para ferromagnetos uniaxiales el parámetro de orden es un escalar.
\item El rango de las interacciones microscópicas.
\end{itemize}
Debido al comportamiento universal de los exponentes críticos, es suficiente analizar sistemas simples más no triviales como es el caso del modelo de Ising. El modelo de Ising considera las interacciones ferromagnéticas entre las moléculas de un material como un modelo discreto, esto consiste en asignar un valor discreto a la orientación relativa del momento dipolar magnético(spin), se asigna $+1$ a una orientación paralela al eje $y$ en el retículo formado por las posiciones discretizadas de las moléculas. ver fig. 1. y se le asigna $-1$ a la orientación anti-paralela. 

\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{LatticeIsing.png} 
\end{center} 
\caption{Retículo de spins}
\end{figure}

Se considera en el análisis la interacción entre spines vecinos $\sigma_{i}$, donde $\sigma_i=\pm1$ representa el spin en la  posición $(x,y)$ del retículo, la fuerza de la interacción entre vecinos se rige por una constante $J$ de modo que el Hamiltoniano del sistema se puede escribir de la siguiente manera.
\begin{equation}
\label{H1}
\mathcal{H}=-J\sum_{\langle i j\rangle}\sigma_i \sigma_j-H\sum_{i=1}^{N}\sigma_i
\end{equation}
donde $H$ es un campo magnético externo aplicado a la región donde se encuentra el retículo de moléculas ,$N$ es el numero total de moléculas en el retículo y la energía $J$ se puede interpretar como un parámetro cuántico de interacción electrostática, en la primera sumatoria se hace la observación que $\langle i j\rangle$ significa la suma de las interacciones de los vecinos más cercanos(vecinos próximos), estos son por ejemplo si se toma a la posición $(x,y)$ sus vecinos serian ${(x,y+1),(x,y-1),(x-1,y),(x+1,y)}$, los vecinos se pueden ver en color azul en la fig 2. y la posición $(x,y)$ se aprecia en color rojo. El primer termino de \ref{H1} representa la energías de interacción introducidas para llevar a un estado ferromagnético ordenado, el segundo termino representa la interacción entre el campo magnético aplicado $H$ y los spins del sistema está interacción es de carácter puramente paramagnético.
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{Neighbor.png} 
\end{center} 
\caption{Vecinos mas cercanos}
\end{figure}
Tomando el caso en le que $H=0$ la ecuación \ref{H1} se convierte en 
\begin{equation}
\label{H2}
\mathcal{H}=-J\sum_{\langle i j\rangle}\sigma_i \sigma_j
\end{equation}
Para resolver el problema de Ising se tiene que encontrar la función de partición canónica
\begin{equation}\label{partition}
Z(T,H,N)=\sum_{\{ \sigma_i\}}\exp(-\beta \mathcal{H})
\end{equation}
con $\beta=\frac{1}{K_B T}$, $K_B$ es la constante de Boltzman, y $T$ es la temperatura en Kelvins. De esta función de partición se tiene que la energía libre por sitio viene dada por
\begin{equation}
g=g(T,H)=\lim_{n\to \infty}\Bigg[-\frac{1}{\beta N}\ln Z_N\Bigg]
\end{equation}
En una dimensión es relativamente sencillo obtener una expresión para está energía libre, por ejemplo por medio la técnica de matrices de transferencia, que también puede usarse en dimensiones mayores, para obtener una solución a la cadena de Ising. Sin embargo está solución es engañosa como fue demostrado por Ising(1925) ya que al ser una función analítica de $T$ y $H$ prohíbe la existencia de magnetización espontánea y de cualquier transición de fase.\\.

Varias técnicas de aproximación han sido desarrolladas para resolver el modelo de Ising en 2 y 3 dimensiones, algunas de ellas bastante sencillas y útiles que conducen a resultados cualitativos razonables para diagramas de fase. Como se mencionó, las transiciones de fase se asocian al comportamiento no-analítico de la energía libre en el límite termodinámico, como consecuencia se debe tener cautela al utilizar truncamientos o expansiones perturbativas alrededor del punto crítico.\\
Lars Onsanger(ver  \cite{Onsanger}, \cite{Pathria}) encontró una solución analítica analítica al modelo de Ising para un retículo cuadrado, con iteraciones de vecinos próximos en la ausencia de campo externo($H=0$), \ref{H2}. Para $T\to T_c$ el calor específico diverge de acuerdo a la forma logarítmica asimptótica
\begin{equation}
c{H=0}\sim \ln|T-T_c|,
\end{equation}
con una temperatura crítica bien definida
\begin{equation}\label{Tc}
T_c=\frac{2J}{K_B \ln(1+\sqrt{2})}
\end{equation}
Aquí se hace un breve presentación de la solución exacta en 1D, en Baxter(ver \cite{Baxter}) se puede hallar métodos de aproximación y una solución en el retículo de Bethe.
\subsection{Solución exacta del Modelo de Ising en 1D}
En una dimensión se tiene que el Hamiltoniano \ref{H1} se convierte en 
\begin{equation}
\mathcal{H}=-J\sum_{i=1}^{N}\sigma_i\sigma_{i+1}-H\sum_{i=1}^{N}\sigma_i
\end{equation}
La función de partición viene dada por 
\begin{equation}
Z_N=\sum_{\{\sigma_i \}}\exp\Bigg[ K+\sum_{i=1}^{N}\sigma_i\sigma_{i+1}+\frac{L}{2}\sum_{i=1}^{N}(\sigma_i+\sigma_{i+1}) \Bigg],
\end{equation}
donde $K=\beta J$, $L=\beta H$ y el segundo término se ha reescrito tomando ventaja de una forma más simétrica, por conveniencia se toman condiciones de frontera periódicas, i.e. $\sigma_{N+1}=\sigma_1$. Es conveniente escribir a la función de partición como 
\begin{equation}\label{canonical_partition_fucntion}
Z_N=\sum_{\sigma_1,\sigma_2,\hdots,\sigma_N}\prod^N_{i=1}T(\sigma_i, \sigma_{i+1})
\end{equation}
donde
\begin{equation}
T(\sigma_i,\sigma_{i+1})=\exp \Big[  K\sigma_i\sigma_{i+1}+\frac{L}{2}(\sigma_i+\sigma_{i+1}) \Big]
\end{equation}
La última expresión puede ser expresada como una matriz de $2\times 2$, cuyos indices son las variables de spin $\sigma_i\pm 1$ y $\sigma_{i+1}\pm 1$. Se define lo que se conoce como \textit{matriz de transferencia},
\begin{equation}
\mathbf{T}=
\begin{pmatrix}
\,T(+,+)\, &\, T(+,-)\,\\
\,T(-,+)\, &\, T(-,-)\,
\end{pmatrix}=
\begin{pmatrix}
\,\exp(K+L)\, &\,\exp(-K)\,\\
\,\exp(-K)\, &\, \exp(K-L)\,
\end{pmatrix}
\end{equation}
usando el formalismo matricial(ver \cite{Silvio}, \cite{Pathria}) se puede expresar la función de partición canónica \ref{canonical_partition_fucntion} como la traza de un producto de $N$ matrices de transferencia
\begin{equation}
Z_N=\text{Tr}(\mathbf{T})^N.
\end{equation}
Con la observación que la matriz de transferencia es simétrica puede ser diagonalizada por una transformación unitaria
\begin{equation*}
\mathbf{U}\mathbf{T}\mathbf{U}^{-1}=\mathbf{D}
\end{equation*}
donde $\mathbf{U}^{-1}=\mathbf{U}^\dagger$ y $\mathbf{D}$ es una matriz diagonal, con esto es posible expresar a la función de partición canónica en términos de las valores propios de la matriz de transferencia
\begin{equation}
Z_N=\text{Tr}(\mathbf{U}^{-1}\mathbf{D}\mathbf{U})^N=\text{Tr}(\mathbf{D})^N=\lambda_1^N +\lambda_2^N
\end{equation}
los valores propios, que vienen de la ecuación propia o secular $\text{det}(\mathbf{T}-\lambda \mathbf{I})=0$, son
\begin{equation}\label{eigen_values}
\lambda_{1,2}=e^K \cosh L \pm \big[ e^{2K} \cosh^2L-2\sinh(2L)\big]^{1/2}
\end{equation}
Estos valores propios son siempre positivos y $\lambda_1>\lambda_2$, con excepción del punto trivial $T=H=0$. Sin presencia de campo externo, $L=0$ se obtiene
\begin{equation}
\lambda_1=2\cosh K\geq \lambda_2=2\sinh K,
\end{equation} 
y se tiene un estado degenerado($\lambda_1=\lambda_2$) en el límite $K\to \infty$ que es equivalente a $T\to 0$. Para obtener la energía libre es conveniente escribir a la función de partición como 
\begin{equation}
Z_N=\lambda_1^N\Bigg[1+\bigg(\frac{\lambda_2}{\lambda_1}\bigg)^N\Bigg]
\end{equation}
Ya que $\lambda_1<\lambda_2$, se puede hallar el límite fácilmente
\begin{equation}
g(T,H)=\lim_{N\to \infty}\Bigg[-\frac{1}{\beta N}\ln Z_N\Bigg]=-\frac{1}{\beta}\ln \lambda_1,
\end{equation}
usando \ref{eigen_values} se obtiene
\begin{equation}
g(T,H)=-\frac{1}{\beta}\ln\Big\{ e^{\beta J}\cosh(\beta H)+\big[ e^{2\beta J} \cosh^2(\beta H)-2\sinh(2\beta J)  \big]^{1/2} \Big\}
\end{equation}
que es una función analítica en $T$ y $H$, de la cual se pueden derivar todas las propiedades termodinámicas del sistema unidimensional. La magnetización promedio por sitio viene dada por 
\begin{equation}
m(T,H)=-\bigg( \frac{\partial g}{\partial H} \bigg)_{T}=\frac{\sinh(\beta h)}{\big[ \sinh^2(\beta H)+e^{-4\beta J} \big]^{1/2}}.
\end{equation}
\section{Metodología}
\subsection{Método de Monte Carlo}
\subsubsection{Ecuación maestra}
Se introduce lo que se conoce como ecuación maestra(ver \cite{Silvio}) para la evolución temporal de procesos estocásticos Markovianos. Si $P(x,t)$ es la probabilidad de encontrar un sistema en el estado microscópico $y$, en el tiempo $t$. Derivando esta probabilidad se tiene
\begin{equation}
\frac{\partial}{\partial t}P(y,t)=T_0-T_f
\end{equation}
donde la tasa de probabilidad de cambiar al estado $y$ esta dada por
\begin{equation}
T_0=\sum_{y'}P(y',t)w(y'\rightarrow y)
\end{equation}
donde $w(y'\rightarrow y)$ puede ser interpretado como la probabilidad que el sistema pase del estado $y'$ al estado $y$ en un intervalo de tiempo muy pequeño. Análogamente la tasa de probabilidad de cambio $y\rightarrow y'$ esta dada por
\begin{equation}
T_f=P(y,t)\sum_{y'}w(y\rightarrow y')
\end{equation}
La ecuación maestra se convierte en 
\begin{equation}\label{masterEq}
\frac{\partial}{\partial t}P(y,t)=\sum_{y'}\Big[P(y',t)w(y'\rightarrow y)-P(y,t)w(y\rightarrow y')\Big]
\end{equation}
Para un estado estacionario $P(y,t)$ no es una función explicita del tiempo, por lo que para el equilibrio se tiene
\begin{equation}
\frac{\partial}{\partial t}P(y,t)=0
\end{equation}
Entonces se tiene la siguiente condición de equilibrio llamado principio de balance detallado
\begin{equation}\label{equi}
P(y',t)w(y'\rightarrow y)=P(y,t)w(y\rightarrow y')
\end{equation}
\subsubsection{Metodo de Monte Carlo}
El estudio de sistemas en equilibrio en mecánica estadística  esta interesado en el calculo de promedios de la forma
\begin{equation}\label{MCavg}
\langle A\rangle=\frac{\displaystyle \sum_{C} A(C) \exp(-\beta\mathcal{H})}{\displaystyle\sum_{C} \exp(-\beta\mathcal{H})}
\end{equation}
donde  la suma indica que se toman en cuenta todas las posibles configuraciones microscópicas del sistema asociado con el Hamiltoniano $\mathcal{H}$, para el caso del modelo de Ising 2D se tiene un retículo de $N=n\times n$ sitios, esto significa que la suma en \ref{MCavg} se hace sobre $2^N=2^{n^2}$ configuraciones. El hecho que el numero de configuraciones crece como $2^{n^2}$ hace que no sea práctico utilizar este tipo de expresión para realizar cálculos numéricos. La solución consiste en realizar promedios sobre un numero mucho mas pequeño de las configuraciones de equilibrio mas representativas  del sistema,
\begin{equation}\label{MCavg2}
\langle A\rangle=\frac{1}{M}\sum^M_{i=1}A_i
\end{equation}
Es importante saber bajo que condiciones se puede realmente obtener el valor esperado de la cantidad $A$ de este promedio aritmético sobre las configuraciones representativas $M$, también es importante saber como seleccionar el numero $M$ de configuraciones representativas. \\
De acuerdo con el método de Monte Carlo se selecciona una secuencia de configuraciones independientes, estas se denominan cadenas de Markov. Algunas de las configuraciones iniciales están lejos del equilibrio pero como función del tiempo se generan muchas mas configuraciones de equilibrio que son utilizadas para promediar \ref{MCavg2}.\\
Como ya fue discutido si se identifica a $w(y\rightarrow y')$ como la probabilidad de transición por unidad de tiempo del estado $y$ a $y'$ se tiene a la ecuación maestra \ref{masterEq} y la condición \ref{equi}.\\
En equilibrio, esto es después de tomar en cuenta varios términos de la secuencia las probabilidades deberían tender a los valores de Gibbs,
\begin{equation}
P_0(y)=\frac{1}{Z}\exp[-\beta\mathcal{H}(y)]
\end{equation}
donde $Z$ la función de partición canónica esta definida en \ref{partition}. De la condición \ref{equi} se tiene
\begin{equation}
P_0(y)w(y\rightarrow y')=P_0(y')w(y'\rightarrow y)
\end{equation}.
Se escogen probabilidades  que satisfacen 
\begin{equation}\label{probTans1}
\frac{w(y\rightarrow y')}{w(y'\rightarrow y)}=\exp (-\beta \Delta \mathcal{H})
\end{equation}
donde $\Delta\mathcal{H}=\mathcal{H}(y')-\mathcal{H}(y)$ es la diferencia de energías entre las configuraciones $y$ y $y'$.\\
Otras dos probabilidades de transición utilizadas en el las simulaciones de monte Carlo son el algoritmo de Glauber y la prescripción de Metropolis, en esta simulación se ha escogido a la prescripción de Metropolis,
\begin{equation}
w(y\rightarrow y')=\left\{
        \begin{array}{ll}
            \frac{1}{\tau}\exp (-\beta \Delta \mathcal{H}), & \quad\;\,\,\,\, \Delta\mathcal{H}> 0 \\\\
            \frac{1}{\tau}, & \quad\quad \Delta\mathcal{H}< 0
        \end{array}
    \right.
\end{equation}
donde el tiempo $\tau$ se interpreta como "step de Monde Carlo".%, se ha escogido $\tau=1$.

\subsubsection{Método de Monte Carlo para el Modelo de Ising}
Se presentan a continuación los pasos del método de Monte Carlo y el diagrama de flujo para generar la cadena de Markov.
\begin{enumerate}
\item Escoger una configuración inicial de spins en el retículo.
\item Se selecciona un sitio al azar y se calcula la energía en ese sitio para las interacciones con los vecinos más cercanos. 
\item Verificar el signo de $E$.
\item Si $E$ es positiva se hace el cambio de spin en el sitio indicado, esto es $\sigma_i=-\sigma_i$.
\item Si $E$ es negativa pero $\exp(-\beta \Delta \mathcal{H})>p_t$, donde $p_t$ es un numero aleatorio entre $0$ y $1$, se cambia al spin, de otra manera se reinicia el ciclo.
\end{enumerate}
%es fácil ver que estos pasos reproducen la prescripción de Metropolis.
con estos pasos se hace una simulación de Monte Carlo con la prescripción de Metropolis.
%\pagebreak
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.5]{FluxDiagram.png} 
\end{center} 
\caption{Diagrama de flujo}
\end{figure}

\subsection{Tiempos de cómputo}
Para poder describir el tiempo de cómputo de la implementación realizada del método de Monte Carlo con la prescripción de Metropolis se corren distintos tipos de simulaciones para poder analizar el comportamiento del tiempo de cómputo con respecto a la variación de otro parámetro
\subsubsection{Tamaño del retículo}
Para poder analizar el comportamiento del tiempo de cómputo en función del tamaño del retículo se hace una simulación para un rango de tamaño de retículos de $N\in[10-500]$ con un intervalo de $10$ entre cada simulación. En la siguiente figura se puede apreciar como el tiempo de cómputo incrementa exponencialmente en función de $N$. Se hace la observación que para se tiene un retículo de $N\times N$, para está simulación el número de iteraciones de Monte Carlo se mantiene fija, $n=10000$
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.64]{time_vrs_lattice_size.png} 
\end{center} 
\caption{Tiempo(s) vrs. N}
\end{figure}

\subsubsection{Temperatura}
De nuevo para analizar el comportamiento del tiempo de cómputo se realizó una simulación con un tamaño de retículo fijo $N=50$, pero se varia la temperatura en un rango de $T\in[1-100]$, en este caso también se fija el número de iteraciones de Monte Carlo en $n=10000$, se hace la importante observación que en todas las simulaciones se usan unidades de física teórica en las que $K_B=1$
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.3]{time_vrs_T.png} 
\end{center} 
\caption{Tiempo(s) vrs. Temperatura}
\end{figure}
El tiempo de computo para $n$(número de iteraciones) y $N$(tamaño del retículo) y una temperatura variable se mantiene constante, esto es consistente con la implementación del algoritmo de Monte Carlo para el modelo de Ising.
Durante esta simulación también se registró como se comporta la magnetización promedio por sitio cuando se hace variar la temperatura, en este caso se puede ver una transición de fase, i.e. se empieza con un material magnetizado que después de una temperatura crítica llega a estar totalmente desmagnetizado, transición ferro-paramagnética.
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.3]{M_vrs_T.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
\subsubsection{Iteraciones de Monte Carlo}
Otro parámetro de interés para evaluar el tiempo de cómputo es el número de iteraciones de Monte Carlo utilizadas durante la simulación, en este caso se hace variar $n\in [100,10000]$, con un tamaño de retículo fijo $N=50$ y temperatura $T=5$, en este caso el tiempo se cómputo es lineal como se puede apreciar el gráfico
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{time_vrs_MC_iterations.png} 
\end{center} 
\caption{Tiempo(s) vrs. no. iteraciones}
\end{figure}

\section{Resultados}
Para poder evaluar el comportamiento del algoritmo de Monte Carlo se puede usar la magnetización promedio, en este caso es interesante ver como el comportamiento del parámetro $J$ que mide describe como se comportan las interacciones entre spins y $H$ la intensidad del campo magnético externo aplicado en el Hamiltoniano \ref{H1}, afectan en la simulación numérica del modelo de Ising, también es de interés ver como $J/H$ afecta el comportamiento en general .\\
Para el caso en el que $H=0$ se tiene el Hamiltoniano \ref{H2} en este caso cuando no hay mas interacción que la que se tiene por los efectos entre spins, para este caso se hace una simulación con $J=1$ el tamaño del retículo es $N=50$ es decir que se tienen $N\times N=250$ sitios, la temperatura varia en un rango $T\in[0.1,10]$ y se tienen $n=10000$ iteraciones de Monte Carlo, se escoge a estado aleatorio del retículo como el estado en el que todos los spins tiene valor $\sigma_i=-1$ es decir que el material ferromagnético esta totalmente magnetizado.
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{PlotMvT_sim1.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
En este caso se puede observar claramente como después de cierta temperatura crítica se observa una transición de fase en el material ferromagnético, una vez alcanzando el equilibrio solo se tienen pequeñas fluctuaciones alrededor de una una magnetización $M=0$.La temperatura crítica en este caso es $T_c=\frac{2}{1+\sqrt{2}}=\approx 2.6919$ en la siguiente figura se identifica a está temperatura con una linea vertical roja.
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{PlotMvT_sim1_v02.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
como se puede apreciar hay efectos por el tamaño finito del retículo. Para investigar como afecta el tamaño del retículo en la estimación numérica del punto crítico se hace otra simulación con las mismas condiciones pero con un retículo de $N=500$ es decir una matriz con $N\times N=250000$ sitios.
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{PlotMvT_sim1_v03.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
Es evidente que al aumentar el tamaño del retículo se tienen una mejor aproximación para el punto crítico, esto sugiere que es posible quitar los efectos de tamaño finito cuando se hacen simulaciones con un retículo más grande. Otro efecto importante de aumentar el tamaño del retículo es que se ve una transición mas suave, consistente con las transiciones de fase continua(transiciones de segundo orden).\\
Para confirmar que la temperatura crítica se puede estimar del resultado de la simulación por el método de Monte Carlo se  corre la simulación en el caso en el que $J=0.5$, por lo que $T_c=1.1346$,
\begin{figure}[H]
\begin{center}
¨\includegraphics[scale=0.6]{PlotMvT_sim1_v04.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
para este caso $T\in[0,4]$, se hace la observación que en estas unidades $K_B=1$. Como se puede notar al cambiar el valor de $J$ se obtuvo una reducción de la temperatura a la que el material pasa a estar totalmente desordenado, desmagnetizado que está de acuerdo al resultado teórico de $T_c$ que se ve marcado en rojo.



Para las mismas condiciones que en el caso anterior pero con la diferencia que ahora se tiene el estado aleaotorio escogido para iniciar la simulación es en el que todos los spins $\sigma_i=+1$. 
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{PlotMvT_sim2.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
se obtiene el resultado esperado, se inicia con un material ferromagnético magnetizado que tiene una transición a un estado sin propiedades magnéticas.\\
Para el caso en el $J/H=1$ y se empieza en el estado en el que todos los spins $\sigma_i=+1$ se obtiene el siguiente resultado
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{PlotMvT_sim3.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
En este caso se puede ver claramente la influencia del campo magnético externo $H$, ya que el sistema tiende a alinearse con este para después empezar a pasar totalmente al desorden característico de la transición de fase. En el repositorio de \texttt{GitHub} \url{https://github.com/Julio-Medina/Ising_Model/tree/main} se pueden encontrar animaciones de estos procesos.\\

En el caso en que $J/H=\frac{1}{10}$ se obtiene el siguiente resultado en el que $T\in[0.1,50]$ 
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{PlotMvT_sim4.png} 
\end{center} 
\caption{Magnetización vrs. Temperatura}
\end{figure}
En este caso también se puede ver el efecto que tiene $H\neq0>J$ de incrementar la temperatura crítica $T_c$ por lo que se necesita simular el sistema a mayores temperaturas para ver la transición de fase, es importante notar que en este caso la temperatura $T_c$ tiene un incremento aproximado de un factor de $10$, esto es consistente con la solución analítica del modelo de Ising \ref{Tc}.



\section{Conclusiones}
El método de Monte Carlo es una buena opción para encontrar el comportamiento aproximado del modelo de Ising, a través de la prescripción de Metropolis. En general se observaron las transiciones de fase como se expuso en los resultados, después de pasar la temperatura crítica el material pierde por completo sus propiedades magnéticas.\\

Los efectos de tamaño finito del retículo pueden "quitar" si se tiene un retículo suficientemente grande y un número de iteraciones de Monte Carlo adecuado, en general del orden de $N$ para obtener resultados razonables durante la simulación del Modelo de Ising en 2D.
\begin{thebibliography}{99}
%% La bibliografía se ordena en orden alfabético respecto al apellido del 
%% autor o autor principal
%% cada entrada tiene su formatado dependiendo si es libro, artículo,
%% tesis, contenido en la web, etc
%Las fuentes de consulta se citan en forma organizada y homogénea, tanto de los libros, de los artículos y, en general, de las obras consultadas, que fueron indispensables indicar o referir en el contenido del trabajo.


\bibitem{Baxter}R.J. Baxter \textit{Exactly solved models in statistical physics}.Academic Press. First Edition.
\bibitem{Salinas}Silvio R.A Salinas. \textit{Introduction to Statistical Physics}. Springer. First Edition.

\bibitem{Onsanger} Lars Onsanger. \textit{Crystal Statistics. I. A Two-Dimensional Model with an Order-Disorder Transition}. Phys. Rev 65, 117, 1944. \url{https://doi.org/10.1103/PhysRev.65.117}

\bibitem{Pathria}R.K. Pathria \textit{Statistical Mechanics}. Elsevier.Third Edition.
%¨\bibitem{}\textit{Finite Difference method}.\url{https://en.wikipedia.org/wiki/Finite_difference_method}

%\bibitem{Feynman} 
%\bibitem{Hopfield} J.J. Hopfield. \textit{Neural Networks and physical systems with emergent collective computational abilities}. \url{https://doi.org/10.1073/pnas.79.8.2554}


%\bibitem{McCulloch} Warren S. McChulloch, Walter H. Pitts. \textit{A LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOUS ACTIVITY}. \url{http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf}



\end{thebibliography}
\end{document}

